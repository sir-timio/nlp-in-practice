{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f14946",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "В качестве бейзлайна используется модель NER, состоящая из RNN поверх эмбеддингов FastText (для получения эмбеддингов нужно запустить ноутбук `train_fasttext.ipynb`)\n",
    "\n",
    "Нормализация брендов и товаров не производится\n",
    "\n",
    "Бейзлайн реализован на библиотеке PyTorch с использованием PyTorch-Lightning для упрощения кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb728ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "\n",
    "def lemmatize(words):\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    \n",
    "    words = []\n",
    "    for token in doc.tokens:\n",
    "        words.append(token.lemma)\n",
    "    return words\n",
    "\n",
    "import re\n",
    "\n",
    "from cyrtranslit import to_cyrillic\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = re.sub('\\d+', '0', text)  # replace numbers to 0\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # remove punctuation\n",
    "    text = text.replace('0', '')\n",
    "    \n",
    "    words = []\n",
    "    for w in text.lower().split():\n",
    "        if bool(re.search('[a-z]', w)) and bool(re.search('[а-я]', w)):\n",
    "            words.append(to_cyrillic(w))\n",
    "        else:\n",
    "            words.append(w)\n",
    "#     words = lemmatize(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e740225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.745439800Z",
     "start_time": "2023-06-08T10:54:49.267906Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchcrf import CRF\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04a339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval==1.2.2\n",
    "# !pip install allennlp==2.10.1\n",
    "# !pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be248c7",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "Полезные функции для работы с BIO-тегами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a45c869f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.749953400Z",
     "start_time": "2023-06-08T10:54:51.748949Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_bio_tagging(row):\n",
    "    \"\"\"\n",
    "    По токенам чека и разметке (то есть выделенным товарам и брендам) строим BIO-теги\n",
    "    \"\"\"\n",
    "    tokens = row[\"tokens\"]\n",
    "    good = row[\"good\"].split(',')[0].split()\n",
    "    brand = row[\"brand\"].split(',')[0].split()\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(good) > 0 and tokens[i:i + len(good)] == good:\n",
    "            tags[i] = \"B-GOOD\"\n",
    "            for j in range(i + 1, i + len(good)):\n",
    "                tags[j] = \"I-GOOD\"\n",
    "        if len(brand) > 0 and tokens[i:i + len(brand)] == brand:\n",
    "            tags[i] = \"B-BRAND\"\n",
    "            for j in range(i + 1, i + len(brand)):\n",
    "                tags[j] = \"I-BRAND\"\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19650c",
   "metadata": {},
   "source": [
    "Прямое и обратное преобразование тегов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b873cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.763150200Z",
     "start_time": "2023-06-08T10:54:51.752090200Z"
    }
   },
   "outputs": [],
   "source": [
    "index_to_tag = [\"O\", \"B-GOOD\", \"I-GOOD\", \"B-BRAND\", \"I-BRAND\", \"PAD\"]\n",
    "tag_to_index = {tag: index for index, tag in enumerate(index_to_tag)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a8c3d",
   "metadata": {},
   "source": [
    "# Datamodule\n",
    "\n",
    "Подготовим данные для модели. Для этого определим наследника `torch.nn.utils.Dataset` - `ReceiptsDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58c5aaec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.770658400Z",
     "start_time": "2023-06-08T10:54:51.763150200Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataset(Dataset):\n",
    "    def __init__(self, df, fasttext):\n",
    "        super().__init__()\n",
    "        self.is_predict = \"tags\" not in df.columns\n",
    "        self.data = df[[\"tokens\", \"good\", \"brand\", \"tags\"]] if not self.is_predict else df[[\"tokens\", \"id\"]]\n",
    "        self.data = self.data.values\n",
    "        self.fasttext = fasttext\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        identifier = 0 if not self.is_predict else self.data[index][1]\n",
    "        tokens = self.data[index][0]\n",
    "        embeddings = self.fasttext.wv[tokens]\n",
    "        goods = self.data[index][1].split(',') if not self.is_predict else list()\n",
    "        brands = self.data[index][2].split(',') if not self.is_predict else list()\n",
    "        tags = self.data[index][3] if not self.is_predict else [\"O\"] * len(tokens)\n",
    "        target = [tag_to_index[tag] for tag in tags]\n",
    "        return identifier, tokens, embeddings, goods, brands, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e6c8a",
   "metadata": {},
   "source": [
    "Для объединения примеров в батчи нужна специальная `collate_fn`, в которой происходит паддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "847269bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.785171100Z",
     "start_time": "2023-06-08T10:54:51.772659Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    ids, tokens_sequence, embeddings_sequence, goods, brands, targets = list(zip(*batch))\n",
    "    embeddings_sequence = pad_sequence([torch.FloatTensor(sequence) for sequence in embeddings_sequence],\n",
    "                                       batch_first=True)\n",
    "    targets = pad_sequence([torch.LongTensor(target) for target in targets], batch_first=True,\n",
    "                           padding_value=tag_to_index[\"PAD\"])\n",
    "    return ids, tokens_sequence, embeddings_sequence, goods, brands, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f45853",
   "metadata": {},
   "source": [
    "Используем LightningDataModule для задания пайплайна\n",
    "\n",
    "1. prepare_data\n",
    "    1. Токенизируем текст\n",
    "    2. Выделяем BIO-теги в размеченной части\n",
    "2. setup\n",
    "    1. Разделяем размеченную выборку на обучающую и валидационную\n",
    "    2. Создаем `ReceiptsDataset` под каждую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d6ab59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.792214800Z",
     "start_time": "2023-06-08T10:54:51.784173Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_dataset_path,\n",
    "                 test_dataset_path,\n",
    "                 fasttext_path,\n",
    "                 val_split_size,\n",
    "                 batch_size,\n",
    "                 num_workers):\n",
    "        super().__init__()\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.test_dataset_path = test_dataset_path\n",
    "        self.fasttext_path = fasttext_path\n",
    "        self.val_split_size = val_split_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.fasttext = FastText.load(self.fasttext_path)\n",
    "        self.train_df = pd.read_csv(self.train_dataset_path).fillna(\"\")\n",
    "        self.test_df = pd.read_csv(self.test_dataset_path)\n",
    "        self.train_df[\"tokens\"] = self.train_df[\"name\"].apply(preprocess_text)\n",
    "        self.test_df[\"tokens\"] = self.test_df[\"name\"].apply(preprocess_text)\n",
    "\n",
    "        self.train_df[\"tags\"] = self.train_df.apply(apply_bio_tagging, axis=1)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size)\n",
    "\n",
    "        self.train_dataset = ReceiptsDataset(self.train_df, self.fasttext)\n",
    "        self.val_dataset = ReceiptsDataset(self.val_df, self.fasttext)\n",
    "        self.predict_dataset = ReceiptsDataset(self.test_df, self.fasttext)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c3aac1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.804924800Z",
     "start_time": "2023-06-08T10:54:51.794242200Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"data/train_supervised_dataset.csv\"\n",
    "TEST_DATASET_PATH = \"data/test_dataset.csv\"\n",
    "FASTTEXT_PATH = \"fasttext_models/fasttext_128.model\"\n",
    "FASTTEXT_DIM = 128\n",
    "VAL_SPLIT_SIZE = 0.1\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c641742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.814434200Z",
     "start_time": "2023-06-08T10:54:51.805924300Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = ReceiptsDataModule(\n",
    "    TRAIN_DATASET_PATH,\n",
    "    TEST_DATASET_PATH,\n",
    "    FASTTEXT_PATH,\n",
    "    VAL_SPLIT_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09717716",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Сначала определим метрику `F1` для задачи NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7db73afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.827296700Z",
     "start_time": "2023-06-08T10:54:51.814434200Z"
    }
   },
   "outputs": [],
   "source": [
    "class F1Score:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        pred = frozenset(x for x in pred)\n",
    "        target = frozenset(x for x in target)\n",
    "        self.tp += len(pred & target)\n",
    "        self.fp += len(pred - target)\n",
    "        self.fn += len(target - pred)\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def get(self):\n",
    "        if self.tp == 0:\n",
    "            return 0.0\n",
    "        precision = self.tp / (self.tp + self.fp)\n",
    "        recall = self.tp / (self.tp + self.fn)\n",
    "        return 2 / (1 / precision + 1 / recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10ae61",
   "metadata": {},
   "source": [
    "Зададим саму модель, ее шаги на обучении, валидации и инференсе, а также способ обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "469a277a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.841898200Z",
     "start_time": "2023-06-08T10:54:51.832413Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 rnn_input_size,\n",
    "                 rnn_hidden_size,\n",
    "                 rnn_num_layers,\n",
    "                 rnn_dropout,\n",
    "                 mlp_hidden_size,\n",
    "                 learning_rate,\n",
    "                 rnn_bidir=True,\n",
    "                 num_tags=-1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lstm = nn.LSTM(input_size=rnn_input_size,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_num_layers,\n",
    "                           batch_first=True,\n",
    "                           dropout=rnn_dropout,\n",
    "                           bidirectional=rnn_bidir,\n",
    "                           )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size + rnn_hidden_size * int(rnn_bidir), mlp_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(mlp_hidden_size, len(index_to_tag)),\n",
    "        )\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "        self.f1_good_train = F1Score()\n",
    "        self.f1_brand_train = F1Score()\n",
    "        self.f1_good_val = F1Score()\n",
    "        self.f1_brand_val = F1Score()\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        sequences, _ = self.lstm(sequences)\n",
    "        logits = self.mlp(sequences)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = -self.crf(logits, targets)\n",
    "        tags_indices_sequence = self.crf.decode(logits)\n",
    "\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_train.update(goods_pred, goods[i])\n",
    "            self.f1_brand_train.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/train\", loss, on_epoch=True, batch_size=len(tags_indices_sequence))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_train\", self.f1_good_train.get())\n",
    "        self.log(\"metric/f1_brand_train\", self.f1_brand_train.get())\n",
    "        self.f1_good_train.reset()\n",
    "        self.f1_brand_train.reset()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = -self.crf(logits, targets)\n",
    "        tags_indices_sequence = self.crf.decode(logits)\n",
    "\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_val.update(goods_pred, goods[i])\n",
    "            self.f1_brand_val.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/val\", loss, batch_size=len(tags_indices_sequence))\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_val\", self.f1_good_val.get())\n",
    "        self.log(\"metric/f1_brand_val\", self.f1_brand_val.get())\n",
    "        self.f1_good_val.reset()\n",
    "        self.f1_brand_val.reset()\n",
    "\n",
    "    def predict_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, _, _, _ = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        tags_indices_sequence = self.crf.decode(logits)\n",
    "        result = list()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"])\n",
    "            brands_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"])\n",
    "            result.append([ids[i], goods_pred, brands_pred])\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18f1cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FASTTEXT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c6e6593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.855590100Z",
     "start_time": "2023-06-08T10:54:51.838893600Z"
    }
   },
   "outputs": [],
   "source": [
    "RNN_INPUT_SIZE = FASTTEXT_DIM\n",
    "RNN_HIDDEN_SIZE = 128\n",
    "RNN_NUM_LAYERS = 3\n",
    "RNN_DROPOUT = 0.3\n",
    "MLP_HIDDEN_SIZE = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "model = ReceiptsModule(\n",
    "    RNN_INPUT_SIZE,\n",
    "    RNN_HIDDEN_SIZE,\n",
    "    RNN_NUM_LAYERS,\n",
    "    RNN_DROPOUT,\n",
    "    MLP_HIDDEN_SIZE,\n",
    "    LEARNING_RATE,\n",
    "    num_tags=len(tag_to_index),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87bbedf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.960372Z",
     "start_time": "2023-06-08T10:54:51.856590400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"ner_crf_lstm_to_cyr_128\"),\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a3d96",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855166b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:08.087368500Z",
     "start_time": "2023-06-08T10:54:52.005941600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | lstm | LSTM       | 1.1 M \n",
      "1 | mlp  | Sequential | 26.3 K\n",
      "2 | crf  | CRF        | 48    \n",
      "------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.324     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6921b71247b4260bf646e29e09a2761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3821658dd58d462dbe17738fa37bfe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/.local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f268f6b04e4bf38a096b7d7759d63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2987dba496c41e5a0aa4d9e37854c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5c80dbcb774afbacadff75d1cc9a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025a879d892942e4b210315de1a6dd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36ff487697e4d0bb0d9f391afa341f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8841a4a2cb54080a916f3c90ae7a5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042b7274b76c4af6943dac7ecb737e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e16f59f05424c9db8374cbc4f66f86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cd501d8f1d47dca080027174c6ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618fbc566c7b4a039a7709f9b532eeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384e2fb32f4a4e44935609481d9afc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d24b20966348f8a134b847c9f1ba54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090056d5e87944b8b3df4d0cad621f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fd7efafea74cceb3435571f5e98313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b38cc33c74cf6b2b9ecf145abe77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca883ccc4e63471998c8f367aa4ea5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a2ac224b514153983e9c527b293240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be173253e6147e0982a6071ef2ec003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8541239d81e45568e6836b21e224cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bc54fe8ec4450cae423a39d1b9c8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3587ec78794e433a89fb381e019ac6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa2cc91d5594a1198fa4d8140b47cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c00732d2a434d8eaa4e8052c6c45364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bc593c1147481695dc29018e3dc42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5abba6e46b48c3a0ddb1f41bf3e228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9888f28f86c4746a6965ac795b363a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb147aaa389440f38fa184967c93f2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42026c8f",
   "metadata": {},
   "source": [
    "Получение итоговых сущностей для тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2a974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.252851200Z",
     "start_time": "2023-06-08T10:57:08.087368500Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.267357500Z",
     "start_time": "2023-06-08T10:57:13.254926100Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(sum(pred, list()), columns=[\"id\", \"good\", \"brand\"])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1809f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dm.test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82b8cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_good'] = submission['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cafb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_brand'] = submission['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054b57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.277342Z",
     "start_time": "2023-06-08T10:57:13.270233600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submissions/submission_crf_lstm_to_cyr_128.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a981f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
